<?xml version="1.0" encoding="UTF-8" ?>

<!--********************************************************************

*********************************************************************-->
<!-- This file was originally part of the book     -->
<!-- (as copied on 2015/07/12)                     -->
<!--                                               -->
<!--   Abstract Algebra: Theory and Applications   -->
<!--                                               -->
<!-- Copyright (C) 1997-2014  Thomas W. Judson     -->

<chapter xml:id="chapter-multivariable-calculus-vector-derivatives" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Vector Derivatives</title>
  <introduction>
    <p>
      In this chapter we review important concepts relating to vector functions and their derivatives.
      As in introductory calculus, the derivative may be seen as giving the rate of change of a particular quantity.
      However, the move to higher dimensions involved with vector functions allows for multiple interpretations of the rate of change of a vector function, and therefore several different notions of the derivative.
      These interpretations are based on combining the following three concepts:
      <ul>
        <li>The <em>gradient</em> of a scalar-valued function.</li>
        <li>The inner product (see <xref ref="definition-inner-product-and-magnitude" text="type-global" />).</li>
        <li>The <em>cross product</em>.</li>
      </ul>
      We will begin by examining the inner and cross products.
    </p>
  </introduction>
  <section xml:id="section-inner-products-and-cross-products">
    <title>Inner Products and Cross Products</title>
    <introduction>
      <p>
        Inner products (also known as dot products) and cross products are two important examples of <q>vector multiplication</q>.
        The inner product is a <em>scalar product</em> meaning that the resulting quantity is a scalar value.
        Likewise, the cross product is a <em>vector product</em> and the resulting quantity is a vector.
        Both products are extremely important in describing vector geometry.
      </p>
    </introduction>
    <subsection xml:id="subsection-inner-products">
      <title>Inner Products</title>
      <p>
        Recall from <xref ref="definition-inner-product-and-magnitude" text="type-global" /> that the inner product of two vectors <m>\xx</m> and <m>\yy</m> in <m>\RR^n</m> is the scalar quantity
        <me>\dotprod{\xx,\yy} = \yy^{T}\xx</me>.
        This product has several nice properties (see <xref ref="theorem-properties-of-the-inner-product" text="type-global" />), but for now we'll consider the property
        <me>\dotprod{\xx,\yy} = \norm{\xx}\norm{\yy}\cos\theta</me>
        where <m>\theta</m> denotes the angle between the vectors <m>\xx</m> and <m>\yy</m> satisfying <m>0\leq\theta\leq\pi</m>.
        An important interpretation of this property is that the inner product, and particularly <m>\frac{\dotprod{\xx,\yy}}{\norm{\xx}\norm{\yy}}</m>, is a measure of the <em>correlation</em> between <m>\xx</m> and <m>\yy</m>.
      </p>
      <example xml:id="example-computing-an-inner-product">
        <title>Computing an Inner Product</title>
        <statement>
          <p>
            Let <m>\xx = \mqty[3 &amp; -4]^{T}</m> and <m>\yy = \mqty[12 &amp; -5]^{T}</m>.
            Are these vectors pointed in the same direction?
          </p>
        </statement>
        <solution>
          <p>
            We can approach this problem as a correlation problem.
            We'll estimate the correlation between <m>\xx</m> and <m>\yy</m> as follows:
            <me>\frac{\dotprod{\xx,\yy}}{\norm{\xx}\norm{\yy}} = \frac{56}{5\cdot13} = \frac{56}{65}</me>.
            Since this quantity is close to <m>1</m>, these vectors appear to be correlated and therefore point in roughly the same direction.
            <aside>
              <p>
                For any nonzero <m>\xx,\yy\in\RR^n</m>, it follows that <m>\frac{\dotprod{\xx,\yy}}{\norm{\xx}\norm{\yy}}\in[-1,1]</m>.
                Values of this quotient close to <m>1</m> imply that the vectors are correlated whereas values close to <m>-1</m> imply that the vectors are <em>anticorrelated</em>.
                Values close to <m>0</m> imply that the vectors are nearly perpendicular.
              </p>
            </aside>
          </p>
        </solution>
      </example>
      <p>
        Inner products are also useful when computing vector <em>projections</em>.
        Intuitively, the projection of one vector <m>\xx</m> onto another vector <m>\yy</m> represents the vector parallel to <m>\yy</m> that is as close as possible to <m>\xx</m>.
        Equivalently, the projection should be the point in <m>\spn{\yy}</m> that is as close as possible to <m>\xx</m>.
      </p>
      <theorem xml:id="theorem-vector-projections">
        <title>Vector Projections</title>
        <idx>vector projection</idx>
        <statement>
          <p>
            Let <m>\xx,\yy\in\RR^n</m> with <m>\yy\neq\vb{0}</m>.
            The <term>projection of <m>\xx</m> onto <m>\yy</m></term> is the vector <m>\proj{\yy}{\xx}</m> given by
            <me>\proj{\yy}{\xx} = \frac{\dotprod{\xx,\yy}}{\dotprod{\yy,\yy}}\yy</me>.
          </p>
        </statement>
        <proof>
          <p>
            The projection should be the point in <m>\spn{\yy}</m> that is as close as possible to <m>\xx</m>.
            Therefore we need to minimize <m>\norm{\xx-\alpha\yy}</m> over <m>\alpha</m>, which is equivalent to minimizing <m>\dotprod{\xx-\alpha\yy,\xx-\alpha\yy}</m>.
            If we expand this inner product, we get
            <me>\dotprod{\xx-\alpha\yy,\xx-\alpha\yy} = \norm{\xx}^2 - 2\alpha\dotprod{\xx,\yy} + \alpha^2\norm{\yy}^2</me>.
            This expression is quadratic in <m>\alpha</m> and can be simplified by completing the square in <m>\alpha</m>:
            <md>
              <mrow>\norm{\xx}^2 - 2\alpha\dotprod{\xx,\yy} + \alpha^2\norm{\yy}^2 &amp; = \norm{\yy}^2\left(\alpha^2 - \frac{2\alpha}{\norm{\yy}^2}\dotprod{\xx,\yy}\right) + \norm{\xx}^2 </mrow>
              <mrow> &amp; = \norm{\yy}^2\left(\alpha - \frac{\dotprod{\xx,\yy}}{\norm{\yy}^2}\right)^2 - \frac{\dotprod{\xx,\yy}^2}{\norm{\yy}^2} + \norm{\xx}^2 </mrow>
            </md>
            Therefore the value of <m>\alpha</m> that makes this quantity as small as possible must be <m>\alpha = \frac{\dotprod{\xx,\yy}}{\norm{\yy}^2}</m>, which means that
            <me>\proj{\yy}{\xx} = \alpha\yy = \frac{\dotprod{\xx,\yy}}{\dotprod{\yy,\yy}}\yy</me>.
          </p>
        </proof>
      </theorem>
      <example xml:id="example-projecting-onto-a-line">
        <title>Projecting onto a Line</title>
        <statement>
          <p>
            Let <m>\vv = \mqty[3 &amp; -2]^{T}</m> let <m>\uu = \mqty[-2 &amp; 2]</m>.
            Find the projection of <m>\vv</m> onto <m>\uu</m>.
          </p>
        </statement>
        <solution>
          <p>
            The projection is given by
            <me>\frac{-10}{8}\mqty[-2 \\ 2] = -\frac{5}{2}\mqty[-1 \\ 1]</me>.
          </p>
        </solution>
      </example>
      <p>
        The formula in <xref ref="theorem-vector-projections" text="type-global" /> can be generalized to subspaces of <m>\RR^n</m>.
        In particular, if <m>S</m> is a subspace of <m>\RR^n</m> with a basis given by columns of a matrix <m>A</m>, then the projection of <m>\xx</m> onto <m>S</m>, <m>\proj{\xx}{S}</m>, is the vector
        <me>\proj{S}{\xx} = A(A^{T}A)^{-1}A^{T}\xx</me>.
        Note that this formula reduces to the formula in <xref ref="theorem-vector-projections" text="type-global" /> in the case that <m>A = [\yy]</m>.
      </p>
      <p>
        Inner products are also connected to the physical concept of work.
        In particular, if a force <m>\mathbf{F}</m> acts on a particle over a displacement <m>\mathbf{d}</m>, then the work done is given by <m>W = \langle\mathbf{F},\mathbf{d}\rangle</m>.
      </p>
    </subsection>
    <subsection xml:id="subsection-cross-products">
      <title>Cross Products</title>
      <p>
        Now we move to the other important example of vector multiplication in this course, the cross product.
      </p>
      <definition xml:id="definition-cross-product">
        <title>Cross Product</title>
        <idx>cross product</idx>
        <statement>
          <p>
            Let <m>\uu,\vv\in\RR^3</m>.
            The <term>cross product</term> of <m>\uu</m> and <m>\vv</m> is the unique vector <m>\uu\times\vv</m> satisfying
            <ol>
              <li><m>\uu\times\vv</m> is perpendicular to both <m>\uu</m> and <m>\vv</m> and has its direction determined by the <em>right-hand rule</em>.</li>
              <li>The magnitude of <m>\uu\times\vv</m> is given by <m>\norm{\uu\times\vv} = \norm{\uu}\norm{\vv}\sin(\theta)</m> where <m>\theta</m> is the angle between <m>\uu</m> and <m>\vv</m>.</li>
            </ol>
          </p>
        </statement>
      </definition>
      <p>
        <xref ref="definition-cross-product" text="type-global" /> is useful for understanding what the cross product gives, but is less useful for actually determining cross products.
        To compute cross products, we use the following computational formula.
      </p>
      <theorem xml:id="theorem-computing-cross-products">
        <title>Computing Cross Products</title>
        <statement>
          <p>
            Let <m>\uu = \smqty[u_1 &amp; u_2 &amp; u_3]^T, \vv = \smqty[v_1 &amp; v_2 &amp; v_3]^T\in\RR^3</m> and let <m>\{\ii,\jj,\kk\}</m> denote the standard basis vectors of <m>\RR^3</m>.
            Then
            <me>\uu\times\vv = \mqty| \ii &amp; \jj &amp; \kk \\ u_1 &amp; u_2 &amp; u_3 \\ v_1 &amp; v_2 &amp; v_3|</me>.
          </p>
        </statement>
      </theorem>
    </subsection>
  </section>
</chapter>
