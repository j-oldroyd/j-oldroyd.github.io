<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>WVWC-AEM Diagonalization of Matrices</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="og:image" content="https://j-oldroyd.github.io/wvwc-advanced-engineering-math/output/html/external/./wvwc-logo.jpg">
<meta property="book:title" content="Advanced Engineering Mathematics Lecture Notes">
<meta property="book:author" content="Jesse Oldroyd">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'color', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.98,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/color', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>// Make *any* pre with class 'sagecell-sage' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-sage',
                       linked: true,
                       languages: ['sage'],
                       evalButtonText: 'Evaluate (Sage)'});
</script><script>// Make *any* pre with class 'sagecell-octave' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-octave',
                       linked: true,
                       languages: ['octave'],
                       evalButtonText: 'Evaluate (Octave)'});
</script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script><script src="https://unpkg.com/lunr/lunr.js"></script><script src="lunr-pretext-search-index.js"></script><script src="https://pretextbook.org/js/0.2/pretext_search.js"></script><link href="https://pretextbook.org/css/0.6/pretext_search.css" rel="stylesheet" type="text/css">
<script>js_version = 0.2</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.2/pretext.js"></script><script>miniversion=0.1</script><script src="https://pretextbook.org/js/0.2/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/0.2/user_preferences.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<script src="https://cdn.geogebra.org/apps/deployggb.js"></script><link href="https://pretextbook.org/css/0.6/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/shell_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/navbar_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.6/setcolors.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" href="" target="_blank"><img src="external/./wvwc-logo.jpg" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="wvwc-advanced-engineering-math.html"><span class="title">Advanced Engineering Mathematics Lecture Notes:</span> <span class="subtitle">West Virginia Wesleyan College</span></a></h1>
<p class="byline">Jesse Oldroyd</p>
</div>
<div id="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms"></span>
</h2>
<div id="searchempty"><span>No results.</span></div>
<ol id="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><a class="index-button button" href="index-1.html" title="Index"><span class="name">Index</span></a><button id="calculator-toggle" class="calculator-toggle button" title="Show calculator" aria-expanded="false" aria-controls="calculator-container"><span class="name">Calc</span></button><div id="calculator-container" class="calculator-container" style="display: none; z-index:100;"><div id="geogebra-calculator"></div></div>
<script>
var ggbApp = new GGBApplet({"appName": "graphing",
    "width": 330,
    "height": 600,
    "showToolBar": true,
    "showAlgebraInput": true,
    "perspective": "G/A",
    "algebraInputPosition": "bottom",
    "scaleContainerClass": "calculator-container",
    "allowUpscale": true,
    "autoHeight": true,
    "disableAutoScale": false},
true);
</script><button id="user-preferences-button" class="user-preferences-button button" title="Modify user preferences"><span id="theavatarbutton" class="name">You!</span><div id="preferences_menu_holder" class="hidden"><ol id="preferences_menu" style="font-family: 'Roboto Serif', serif;">
<li data-env="avatar" tabindex="-1">Choose avatar<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden avatar">
<li data-val="You!" tabindex="-1">
<span id="theYou!" class="avatarcheck">‚úîÔ∏è</span>You!</li>
<li data-val="üò∫" tabindex="-1">
<span id="theüò∫" class="avatarcheck"></span>üò∫</li>
<li data-val="üë§" tabindex="-1">
<span id="theüë§" class="avatarcheck"></span>üë§</li>
<li data-val="üëΩ" tabindex="-1">
<span id="theüëΩ" class="avatarcheck"></span>üëΩ</li>
<li data-val="üê∂" tabindex="-1">
<span id="theüê∂" class="avatarcheck"></span>üê∂</li>
<li data-val="üêº" tabindex="-1">
<span id="theüêº" class="avatarcheck"></span>üêº</li>
<li data-val="üåà" tabindex="-1">
<span id="theüåà" class="avatarcheck"></span>üåà</li>
</ol>
</li>
<li data-env="fontfamily" tabindex="-1">Font family<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fontfamily">
<li data-val="face" data-change="OS" tabindex="-1" style="font-family: 'Open Sans'">
<span id="theOS" class="ffcheck">‚úîÔ∏è</span><span class="name">Open Sans</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
<li data-val="face" data-change="RS" tabindex="-1" style="font-family: 'Roboto Serif'">
<span id="theRS" class="ffcheck"></span><span class="name">Roboto Serif</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
</ol>
</li>
<li data-env="font" tabindex="-1">Adjust font<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fonts">
<li>Size</li>
<li><span id="thesize">12</span></li>
<li data-val="size" data-change="-1" tabindex="-1" style="font-size: 80%">Smaller</li>
<li data-val="size" data-change="1" tabindex="-1" style="font-size: 110%">Larger</li>
<li>Width</li>
<li><span id="thewdth">100</span></li>
<li data-val="wdth" data-change="-5" tabindex="-1" style="font-variation-settings: 'wdth' 60">narrower</li>
<li data-val="wdth" data-change="5" tabindex="-1" style="font-variation-settings: 'wdth' 150">wider</li>
<li>Weight</li>
<li><span id="thewght">400</span></li>
<li data-val="wght" data-change="-50" tabindex="-1" style="font-weight: 200">thinner</li>
<li data-val="wght" data-change="50" tabindex="-1" style="font-weight: 700">heavier</li>
<li>Letter spacing</li>
<li>
<span id="thelspace">0</span><span class="byunits">/200</span>
</li>
<li data-val="lspace" data-change="-1" tabindex="-1">closer</li>
<li data-val="lspace" data-change="1" tabindex="-1">f a r t h e r</li>
<li>Word spacing</li>
<li>
<span id="thewspace">0</span><span class="byunits">/50</span>
</li>
<li data-val="wspace" data-change="-1" tabindex="-1">smaller‚ÄÖgap‚ÄÉ</li>
<li data-val="wspace" data-change="1" tabindex="-1">larger‚ÄÉgap</li>
<li>Line Spacing</li>
<li>
<span id="theheight">135</span><span class="byunits">/100</span>
</li>
<li data-val="height" data-change="-5" tabindex="-1" style="line-height: 1">closer<br>together</li>
<li data-val="height" data-change="5" tabindex="-1" style="line-height: 1.75">further<br>apart</li>
</ol>
</li>
<li data-env="atmosphere" tabindex="-1">Light/dark mode<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden atmosphere">
<li data-val="default" tabindex="-1">
<span id="thedefault" class="atmospherecheck">‚úîÔ∏è</span>default</li>
<li data-val="pastel" tabindex="-1">
<span id="thepastel" class="atmospherecheck"></span>pastel</li>
<li data-val="darktwilight" tabindex="-1">
<span id="thedarktwilight" class="atmospherecheck"></span>twilight</li>
<li data-val="dark" tabindex="-1">
<span id="thedark" class="atmospherecheck"></span>dark</li>
<li data-val="darkmidnight" tabindex="-1">
<span id="thedarkmidnight" class="atmospherecheck"></span>midnight</li>
</ol>
</li>
<li data-env="ruler" tabindex="-1">Reading ruler<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden ruler">
<li data-val="none" tabindex="-1">
<span id="thenone" class="rulercheck">‚úîÔ∏è</span>none</li>
<li data-val="underline" tabindex="-1">
<span id="theunderline" class="rulercheck"></span>underline</li>
<li data-val="lunderline" tabindex="-1">
<span id="thelunderline" class="rulercheck"></span>L-underline</li>
<li data-val="greybar" tabindex="-1">
<span id="thegreybar" class="rulercheck"></span>grey bar</li>
<li data-val="lightbox" tabindex="-1">
<span id="thelightbox" class="rulercheck"></span>light box</li>
<li data-val="sunrise" tabindex="-1">
<span id="thesunrise" class="rulercheck"></span>sunrise</li>
<li data-val="sunriseunderline" tabindex="-1">
<span id="thesunriseunderline" class="rulercheck"></span>sunrise underline</li>
<li class="moveQ">Motion by:</li>
<li data-val="mouse" tabindex="-1">
<span id="themouse" class="motioncheck">‚úîÔ∏è</span>follow the mouse</li>
<li data-val="arrow" tabindex="-1">
<span id="thearrow" class="motioncheck"></span>up/down arrows - not yet</li>
<li data-val="eye" tabindex="-1">
<span id="theeye" class="motioncheck"></span>eye tracking - not yet</li>
</ol>
</li>
</ol></div></button><span class="treebuttons"><a class="previous-button button" href="section-orthogonal-transformations.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="chapter-linear-eigenvalues-eigenvectors.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="part-multivariable-calculus.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{physics}\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\CC}{\mathbb{C}}
\renewcommand{\th}{\text{th}}
\newcommand{\xx}{\mathbf{x}}
\newcommand{\xxp}{\mathbf{x}^\prime}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\yyp}{\mathbf{y}^\prime}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\zzp}{\mathbf{z}^\prime}
\newcommand{\ii}{\mathbf{i}}
\newcommand{\jj}{\mathbf{j}}
\newcommand{\kk}{\mathbf{k}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\uup}{\mathbf{u}^\prime}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\vvp}{\mathbf{v}^\prime}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\ee}{\mathbf{e}}
\newcommand{\nn}{\mathbf{n}}
\newcommand{\rr}{\mathbf{r}}
\newcommand{\rrp}{\mathbf{r}^\prime}
\newcommand{\ff}{\mathbf{f}}
\newcommand{\FF}{\mathbf{F}}
\renewcommand{\SS}{\mathbf{S}}
\newcommand{\TT}{\mathbf{T}}
\newcommand{\col}[1]{\operatorname{col}{#1}}
\newcommand{\dotprod}[1]{\left\langle #1 \right\rangle}
\newcommand{\nul}[1]{\operatorname{null}{#1}}
\newcommand{\spn}[1]{\operatorname{span}{#1}}
\newcommand{\rowop}[2][]{\overset{#2}{\underset{#1}{\sim}}}
\newcommand{\Sum}[2]{\sum_{#1}^{#2}}
\newcommand{\Int}[2]{\int_{#1}^{#2}}
\newcommand{\limit}[2]{\lim_{#1\to#2}}
\newcommand{\Laplace}[1]{\mathcal{L}\left\{#1\right\}}
\newcommand{\iLaplace}[1]{\mathcal{L}^{-1}\left\{#1\right\}}
\newcommand{\vecm}[1]{\boldsymbol{#1}}
\newcommand{\ivec}[1]{
\renewcommand{\arraystretch}{.8}
\begin{bmatrix}#1\end{bmatrix}
      }
\newcommand{\proj}[2]{\operatorname{proj}_{#1} #2}
\newcommand{\del}{\nabla} 
\renewcommand{\div}{\grad\cdot}
\newcommand{\divt}{\operatorname{div}}
\newcommand{\curlt}{\operatorname{curl}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar"><nav id="ptx-toc" class="depth3"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="front-colophon.html" class="internal"><span class="title">Colophon</span></a></div></li>
<li><div class="toc-item"><a href="acknowledgement.html" class="internal"><span class="title">Acknowledgements</span></a></div></li>
<li><div class="toc-item"><a href="preface.html" class="internal"><span class="title">Preface</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="part-linear-algebra.html" class="internal"><span class="codenumber">I</span> <span class="title">Linear Algebra</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="chapter-linear-algebra-matrices.html" class="internal"><span class="codenumber">1</span> <span class="title">Introduction to Matrix Algebra</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-matrices-vectors-and-linear-combinations.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Matrices, Vectors and Linear Combinations</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-multiplication.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Matrix Multiplication</span></a></div></li>
<li><div class="toc-item"><a href="section-systems-of-linear-equations.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Systems of Linear Equations</span></a></div></li>
<li>
<div class="toc-item"><a href="section-linear-independence.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Linear Independence</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-linear-independence.html#subsection-span" class="internal"><span class="title">Span</span></a></div></li>
<li><div class="toc-item"><a href="section-linear-independence.html#subsection-definition-and-examples-of-linear-independence" class="internal"><span class="title">Definition and Examples of Linear Independence</span></a></div></li>
<li><div class="toc-item"><a href="section-linear-independence.html#subsection-bases-in--rr-n-" class="internal"><span class="title">Bases in <span class="process-math">\(\RR^n\)</span></span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="section-existence-of-solutions.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Existence of Solutions</span></a></div></li>
<li><div class="toc-item"><a href="section-determinants.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Determinants</span></a></div></li>
<li>
<div class="toc-item"><a href="section-matrix-inverses.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Matrix Inverses</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-matrix-inverses.html#subsection-computing-the-inverse-of-a-matrix" class="internal"><span class="title">Computing the Inverse of a Matrix</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-inverses.html#subsection-invertible-matrix-algorithm" class="internal"><span class="title">The Invertible Matrix Algorithm</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="section--LU-decomposition.html" class="internal"><span class="codenumber">1.8</span> <span class="title"><span class="process-math">\(LU\)</span> Decomposition</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chapter-linear-eigenvalues-eigenvectors.html" class="internal"><span class="codenumber">2</span> <span class="title">Eigenvalues and Eigenvectors</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="section-finding-eigenvalues-and-eigenvectors.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Finding Eigenvalues and Eigenvectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-finding-eigenvalues-and-eigenvectors.html#subsection-computing-eigenvalues-and-eigenvectors" class="internal"><span class="title">Computing Eigenvalues and Eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="section-finding-eigenvalues-and-eigenvectors.html#subsection-algebraic-and-geometric-multiplicities-of-eigenvalues" class="internal"><span class="title">Algebraic and Geometric Multiplicities of Eigenvalues</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="section-eigenvalue-problems.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Eigenvalue Problems</span></a></div></li>
<li><div class="toc-item"><a href="section-orthogonal-transformations.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Orthogonal Transformations</span></a></div></li>
<li class="active">
<div class="toc-item"><a href="section-diagonalization-of-matrices.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Diagonalization of Matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-diagonalization-of-matrices.html#subsection-eigenbases" class="internal"><span class="title">Eigenbases</span></a></div></li>
<li><div class="toc-item"><a href="section-diagonalization-of-matrices.html#subsection-diagonalization" class="internal"><span class="title">Diagonalization</span></a></div></li>
<li><div class="toc-item"><a href="section-diagonalization-of-matrices.html#subsection-diagonalizations-of-symmetric-and-hermitian-matrices" class="internal"><span class="title">Diagonalizations of Symmetric and Hermitian Matrices</span></a></div></li>
<li><div class="toc-item"><a href="section-diagonalization-of-matrices.html#subsection-analytic-functions-of-matrices" class="internal"><span class="title">Analytic Functions of Matrices</span></a></div></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="part-multivariable-calculus.html" class="internal"><span class="codenumber">II</span> <span class="title">Multivariable Calculus</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="chapter-multivariable-calculus-vector-derivatives.html" class="internal"><span class="codenumber">3</span> <span class="title">Vector Derivatives</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="section-inner-products-and-cross-products.html" class="internal"><span class="codenumber">3.1</span> <span class="title">Inner Products and Cross Products</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-inner-products-and-cross-products.html#subsection-inner-products" class="internal"><span class="title">Inner Products</span></a></div></li>
<li><div class="toc-item"><a href="section-inner-products-and-cross-products.html#subsection-cross-products" class="internal"><span class="title">Cross Products</span></a></div></li>
<li><div class="toc-item"><a href="section-inner-products-and-cross-products.html#subsection-computing-inner-and-cross-products-using-technology" class="internal"><span class="title">Computing Inner and Cross Products Using Technology</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-vector-functions.html" class="internal"><span class="codenumber">3.2</span> <span class="title">Vector Functions</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-vector-functions.html#subsection-visualizing-vector-functions" class="internal"><span class="title">Visualizing Vector Functions</span></a></div></li>
<li><div class="toc-item"><a href="section-vector-functions.html#subsection-vector-functions-and-motion" class="internal"><span class="title">Vector Functions and Motion</span></a></div></li>
<li><div class="toc-item"><a href="section-vector-functions.html#subsection-derivatives-of-vector-products" class="internal"><span class="title">Derivatives of Vector Products</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-arc-length-and-components-of-acceleration.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Arc Length and Components of Acceleration</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-arc-length-and-components-of-acceleration.html#subsection-arc-length" class="internal"><span class="title">Arc Length</span></a></div></li>
<li><div class="toc-item"><a href="section-arc-length-and-components-of-acceleration.html#subsection-components-of-acceleration" class="internal"><span class="title">Components of Acceleration</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-gradients-and-potentials.html" class="internal"><span class="codenumber">3.4</span> <span class="title">Gradients and Potentials</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-gradients-and-potentials.html#subsection-gradients" class="internal"><span class="title">Gradients</span></a></div></li>
<li><div class="toc-item"><a href="section-gradients-and-potentials.html#subsection-potential-functions" class="internal"><span class="title">Potential Functions</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-divergence-and-curl-of-vector-fields.html" class="internal"><span class="codenumber">3.5</span> <span class="title">Divergence and Curl of Vector Fields</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-divergence-and-curl-of-vector-fields.html#subsection-divergence" class="internal"><span class="title">Divergence</span></a></div></li>
<li><div class="toc-item"><a href="section-divergence-and-curl-of-vector-fields.html#subsection-curl" class="internal"><span class="title">Curl</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="section-sage-examples.html" class="internal"><span class="codenumber">3.6</span> <span class="title">Sage Examples</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="chapter-multivariable-calculus-vector-integrals.html" class="internal"><span class="codenumber">4</span> <span class="title">Vector Integrals</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="section-line-integrals.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Line Integrals</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-line-integrals.html#subsection-scalar-line-integrals" class="internal"><span class="title">Scalar Line Integrals</span></a></div></li>
<li><div class="toc-item"><a href="section-line-integrals.html#subsection-line-integrals-of-vector-fields" class="internal"><span class="title">Line Integrals of Vector Fields</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-path-independence-and-the-fundamental-theorem-of-line-integrals.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Path Independence and the Fundamental Theorem of Line Integrals</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-path-independence-and-the-fundamental-theorem-of-line-integrals.html#subsection-path-independence" class="internal"><span class="title">Path Independence</span></a></div></li>
<li><div class="toc-item"><a href="section-path-independence-and-the-fundamental-theorem-of-line-integrals.html#subsection-fundamental-theorem-of-line-integrals" class="internal"><span class="title">Fundamental Theorem of Line Integrals</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-green-s-theorem.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Green's Theorem</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-green-s-theorem.html#subsection-green-s-theorem-for-circulation-integrals" class="internal"><span class="title">Green's Theorem for Circulation Integrals</span></a></div></li>
<li><div class="toc-item"><a href="section-green-s-theorem.html#subsection-green-s-theorem-for-flux-integrals" class="internal"><span class="title">Green's Theorem for Flux Integrals</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-surface-integrals.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Surface Integrals</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-surface-integrals.html#subsection-surfaces-in--rr-3-" class="internal"><span class="title">Surfaces in <span class="process-math">\(\RR^3\)</span></span></a></div></li>
<li><div class="toc-item"><a href="section-surface-integrals.html#subsection-surface-integrals" class="internal"><span class="title">Surface Integrals</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-the-divergence-theorem-and-applications.html" class="internal"><span class="codenumber">4.5</span> <span class="title">The Divergence Theorem and Its Applications</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-the-divergence-theorem-and-applications.html#subsection-the-divergence-theorem" class="internal"><span class="title">The Divergence Theorem</span></a></div></li>
<li><div class="toc-item"><a href="section-the-divergence-theorem-and-applications.html#subsection-applications-of-the-divergence-theorem" class="internal"><span class="title">Applications of the Divergence Theorem</span></a></div></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="backmatter.html" class="internal"><span class="title">Back Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="appendix-gfdl.html" class="internal"><span class="codenumber">A</span> <span class="title">GNU Free Documentation License</span></a></div></li>
<li><div class="toc-item"><a href="index-1.html" class="internal"><span class="title">Index</span></a></div></li>
<li><div class="toc-item"><a href="colophon-2.html" class="internal"><span class="title">Colophon</span></a></div></li>
</ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content">
<section class="section" id="section-diagonalization-of-matrices"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">2.4</span> <span class="title">Diagonalization of Matrices</span>
</h2>
<section class="introduction" id="introduction-2"><div class="para" id="p-228">In this section we consider bases of <span class="process-math">\(\mathbb{R}^n\)</span> that are associated with eigenvectors a square matrix <span class="process-math">\(A\)</span> known as eigenbases (see <a href="" class="xref" data-knowl="./knowl/definition-eigenbases.html" title="Definition 2.1.14: Eigenbases">Definition¬†2.1.14</a>). The benefit to looking at such a basis instead of using the standard basis of <span class="process-math">\(\RR^n\)</span> is that the eigenbasis will make products involving <span class="process-math">\(A\)</span> much simpler through a process known as <em class="emphasis">diagonalization</em>.</div></section><section class="subsection" id="subsection-eigenbases"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Eigenbases</span>
</h3>
<div class="para logical" id="p-229">
<div class="para">Recall that a basis of <span class="process-math">\(\RR^n\)</span> is a linearly independent collection of <span class="process-math">\(n\)</span> vectors in <span class="process-math">\(\RR^n\)</span> (see also <a href="" class="xref" data-knowl="./knowl/definition-basis-of--rr-n-.html" title="Definition 1.4.7: Basis of \RR^n">Definition¬†1.4.7</a>). The defining characteristic of a basis is this: if <span class="process-math">\(\qty{\vb{b}_1,\ldots,\vb{b}_n}\)</span> is a basis of <span class="process-math">\(\RR^n\)</span> and if <span class="process-math">\(\vb{x}\in\RR^n\text{,}\)</span> then there exists a unique set of scalars <span class="process-math">\(c_1,\ldots,c_n\)</span> such that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/definition-basis-of--rr-n-.html ./knowl/definition-eigenbases.html">
\begin{equation*}
\xx = \sum_{i=1}^{n}c_i\vb{b}_i\text{.}
\end{equation*}
</div>
<div class="para">This makes it possible to use the basis as a coordinate system in <span class="process-math">\(\RR^n\text{.}\)</span> Therefore we may view an eigenbasis (<a href="" class="xref" data-knowl="./knowl/definition-eigenbases.html" title="Definition 2.1.14: Eigenbases">Definition¬†2.1.14</a>) of a matrix <span class="process-math">\(A\)</span> as a particular coordinate system that is well-suited to calculations involving <span class="process-math">\(A\text{,}\)</span> an idea which we make precise below.</div>
</div>
<article class="example example-like" id="example-using-an-eigenbasis-to-compute-a-matrix-product"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.1</span><span class="period">.</span><span class="space"> </span><span class="title">Using an Eigenbasis to Compute a Matrix Product.</span>
</h4>
<div class="para logical" id="p-230">
<div class="para">Let</div>
<div class="displaymath process-math">
\begin{equation*}
A = \mqty[-2 &amp; 3 \\ -4 &amp; 5]\text{ and }\vb{b} = \mqty[-2 \\ 10]\text{.}
\end{equation*}
</div>
<div class="para">Given that</div>
<div class="displaymath process-math">
\begin{equation*}
\vv_1 = \mqty[1\\1]\text{ and }\vv_2 = \mqty[3\\4]
\end{equation*}
</div>
<div class="para">are eigenvectors of <span class="process-math">\(A\)</span> with corresponding eigenvalues <span class="process-math">\(\lambda_1 = 1\)</span> and <span class="process-math">\(\lambda_2 = 2\text{,}\)</span> find <span class="process-math">\(A^{100}\bb\text{.}\)</span>
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-27" id="solution-27"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-27"><div class="solution solution-like">
<div class="para" id="p-231">First, note that <span class="process-math">\(\qty{\vv_1,\vv_2}\)</span> is a basis of <span class="process-math">\(\RR^2\text{.}\)</span> Therefore it's an eigenbasis since each vector is an eigenvector of <span class="process-math">\(A\text{.}\)</span> <aside class="aside aside-like" id="aside-4"><h5 class="heading"><span class="title">Bases in <span class="process-math">\(\RR^2\)</span>.</span></h5>
<div class="para" id="p-232">One way to see that <span class="process-math">\(\qty{\vv_1,\vv_2}\)</span> must be a basis of <span class="process-math">\(\RR^2\)</span> is to observe that <span class="process-math">\(\vv_2\)</span> is not a scalar multiple of <span class="process-math">\(\vv_1\)</span> and so the two vectors are linearly independent. Then <span class="process-math">\(\qty{\vv_1,\vv_2}\)</span> is a set of two linearly independent vectors in the two-dimensional vector space <span class="process-math">\(\RR^2\text{,}\)</span> and so this set must be a basis of <span class="process-math">\(\RR^2\text{.}\)</span>
</div></aside>
</div> <div class="para logical" id="p-233">
<div class="para">Since <span class="process-math">\(\qty{\vv_1,\vv_2}\)</span> is a basis of <span class="process-math">\(\RR^2\)</span> then there exist scalars <span class="process-math">\(c_1,c_2\)</span> such that <span class="process-math">\(\bb = c_1\vv_1 + c_2\vv_2\text{.}\)</span> We can find these scalars by row reduction of the augmented matrix <span class="process-math">\(\mqty[\vv_1 &amp; \vv_2 &amp; \bb]\text{.}\)</span> This reduces to</div>
<div class="displaymath process-math">
\begin{equation*}
\mqty[1 &amp; 0 &amp; -38 \\ 0 &amp; 1 &amp; 12]\text{,}
\end{equation*}
</div>
<div class="para">and so <span class="process-math">\(c_1 = -38, c_2 = 12\)</span> and</div>
<div class="displaymath process-math">
\begin{equation*}
\bb = -38\vv_1 + 12\vv_2\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="p-234">
<div class="para">Now that we've written <span class="process-math">\(\bb\)</span> in terms of the eigenbasis <span class="process-math">\(\qty{\vv_1,\vv_2}\text{,}\)</span> the computation of <span class="process-math">\(A^{100}\bb\)</span> becomes almost trivial:</div>
<div class="displaymath process-math" id="md-15">
\begin{align*}
A^{100}\bb &amp; = A^{100}(-38\vv_1 + 12\vv_2) \\
&amp; = -38 A^{100}\vv_1 + 12 A^{100}\vv_2 \\
&amp; = -38 \vv_1 + 12\cdot 2^{100}\vv_2 \\
&amp; = \mqty[-38 + 36(2^{100}) \\ -38 + 48(2^{100})] \text{.}
\end{align*}
</div>
<div class="para"><aside class="aside aside-like" id="aside-5"><div class="para logical" id="p-235">
<div class="para">The second to last line of this computation makes use of the fact that</div>
<div class="displaymath process-math">
\begin{equation*}
A^n\xx = \lambda^n\xx
\end{equation*}
</div>
<div class="para">for any eigenvector <span class="process-math">\(\xx\)</span> of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda\text{.}\)</span>
</div>
</div></aside></div>
</div>
</div></div>
</div></article><pre class="ptx-sagecell sagecell-octave" id="sage-16"><script type="text/x-sage">format short
A = [1, 3, -2; 1, 4, 10]
rref(A) # reduces to find c_1, c_2
</script></pre>
<div class="para" id="p-236">
<a href="" class="xref" data-knowl="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html" title="Example 2.4.1: Using an Eigenbasis to Compute a Matrix Product">Example¬†2.4.1</a> shows that the existence of an eigenbasis can greatly simplify certain computations. Unfortunately, not every matrix has a corresponding eigenbasis (see <a href="" class="xref" data-knowl="./knowl/definition-defective-matrices.html" title="Definition 2.1.12: Defective Matrices">Definition¬†2.1.12</a>). However, the following theorem gives a simple condition that can be used to guarantee the existence of an eigenbasis.</div>
<article class="theorem theorem-like" id="theorem-distinct-eigenvalues-and-eigenbases"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.2</span><span class="period">.</span><span class="space"> </span><span class="title">Distinct Eigenvalues and Eigenbases.</span>
</h4>
<div class="para" id="p-237">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix and suppose that <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> distinct eigenvalues (equivalently, no eigenvalue is repeated). Then <span class="process-math">\(A\)</span> has an eigenbasis.</div></article><article class="hiddenproof" id="proof-5"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-5"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-5"><article class="hiddenproof"><div class="para" id="p-238">The proof of this statement follows from the fact that eigenvectors corresponding to distinct eigenvalues must be linearly independent, so we'll prove this first. So let <span class="process-math">\(\qty{\lambda_i}_{i=1}^n\)</span> denote the eigenvalues of <span class="process-math">\(A\)</span> and let <span class="process-math">\(\xx_i\)</span> denote an eigenvector of <span class="process-math">\(A\)</span> corresponding to <span class="process-math">\(\lambda_i\text{.}\)</span> We'll show that <span class="process-math">\(\qty{\xx_i}_{i=1}^n\)</span> is a linearly independent set. As this will then be a set of <span class="process-math">\(n\)</span> linearly independent vectors in <span class="process-math">\(\RR^n\text{,}\)</span> this is enough to show that it's a basis as well.</div> <div class="para logical" id="p-239">
<div class="para">Suppose that we have scalars <span class="process-math">\(\qty{c_i}\)</span> such that <span class="process-math">\(\sum_{i=1}^n c_i\xx_i = \vb{0}\text{.}\)</span> We need to show that <span class="process-math">\(c_1=\ldots=c_n=0\text{.}\)</span> Now, since each <span class="process-math">\(\xx_i\)</span> is an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda_i\text{,}\)</span> it follows that</div>
<div class="displaymath process-math">
\begin{equation*}
A\qty(\sum_{i=1}^n c_i\xx_i) = \sum_{i=1}^n c_i A\xx_i = \sum_{i=1}^n c_i\lambda_i\xx_i\text{.}
\end{equation*}
</div>
<div class="para">Since <span class="process-math">\(A\vb{0} = \vb{0}\)</span> as well, we have</div>
<div class="displaymath process-math">
\begin{equation*}
\sum_{i=1}^n c_i\lambda_i\xx_i = \vb{0}\text{.}
\end{equation*}
</div>
<div class="para">We can also multiply the original equation <span class="process-math">\(\sum_{i=1}^{n}c_i\xx_i = \vb{0}\)</span> by <span class="process-math">\(\lambda_1\)</span> to get</div>
<div class="displaymath process-math">
\begin{equation*}
\sum_{i=1}^{n}\lambda_1 c_i\xx_i = \vb{0}\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="p-240">
<div class="para">Subtracting the previous two equations allows us to write</div>
<div class="displaymath process-math">
\begin{equation*}
\vb{0} = \sum_{i=1}^n c_i (\lambda_i - \lambda_1)\xx_i = \sum_{i=2}^n c_i(\lambda_i-\lambda_1)\xx_i = \sum_{i=2}^{n}d_i \xx_i
\end{equation*}
</div>
<div class="para">where <span class="process-math">\(d_i = c_i(\lambda_i-\lambda_1)\text{.}\)</span> Now we can repeat the above process and write</div>
<div class="displaymath process-math">
\begin{equation*}
\sum_{i=2}^n d_i\lambda_i\xx_i = \vb{0} = \sum_{i=2}^n d_i\lambda_2\xx_i
\end{equation*}
</div>
<div class="para">which gives (after subtracting)</div>
<div class="displaymath process-math">
\begin{equation*}
\vb{0} = \sum_{i=2}^n d_i (\lambda_i-\lambda_2)\xx_i = \sum_{i=3}^n d_i (\lambda_i-\lambda_2)\xx_i = \sum_{i=3}^n e_i\xx_i
\end{equation*}
</div>
<div class="para">where <span class="process-math">\(e_i = (\lambda_i-\lambda_2)d_i = (\lambda_i-\lambda_2)(\lambda_i-\lambda_1)c_i\text{.}\)</span> Continuing this process, we are left with the equation</div>
<div class="displaymath process-math">
\begin{equation*}
\vb{0} = (\lambda_n-\lambda_{n-1})(\lambda_n-\lambda_{n-2})\cdots(\lambda_n-\lambda_1)c_n\xx_n\text{,}
\end{equation*}
</div>
<div class="para">which forces <span class="process-math">\(c_n = 0\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-241">
<div class="para">Now we are left with</div>
<div class="displaymath process-math">
\begin{equation*}
\sum_{i=1}^{n-1}c_{i}\xx_i = \vb{0}
\end{equation*}
</div>
<div class="para">since we can safely disregard <span class="process-math">\(c_n\xx_n\text{.}\)</span> But there's nothing stopping us from applying the previous trick to this new sum, which will eventually show that <span class="process-math">\(c_{n-1} = 0\text{,}\)</span> and then <span class="process-math">\(c_{n-2} = 0\text{,}\)</span> and so on. Therefore</div>
<div class="displaymath process-math">
\begin{equation*}
c_1=\ldots = c_n = 0
\end{equation*}
</div>
<div class="para">and the set <span class="process-math">\(\qty{\xx_i}_{i=1}^n\)</span> must be linearly independent, which was what we needed to prove.</div>
</div></article></div></section><section class="subsection" id="subsection-diagonalization"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Diagonalization</span>
</h3>
<div class="para logical" id="p-242">
<div class="para">Now we'll take a closer look at just what we did in <a href="" class="xref" data-knowl="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html" title="Example 2.4.1: Using an Eigenbasis to Compute a Matrix Product">Example¬†2.4.1</a> to compute <span class="process-math">\(A^{100}\bb\)</span> (or, more simply, <span class="process-math">\(A\bb\)</span>). First, we found <span class="process-math">\(c_1,c_2\)</span> such that <span class="process-math">\(\bb = c_1\vv_1 + c_2\vv_2\text{.}\)</span> If we let <span class="process-math">\(P = \smqty[\vv_1&amp;\vv_2]\)</span> then this is equivalent to solving the matrix equation</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html">
\begin{equation*}
P\mqty[c_1 \\ c_2] = \bb\implies \mqty[c_1 \\ c_2] = P^{-1}\bb\text{.}
\end{equation*}
</div>
<div class="para">We therefore view <span class="process-math">\(P^{-1}\bb\)</span> as the coordinates of <span class="process-math">\(\bb\)</span> with respect to the eigenbasis <span class="process-math">\(\qty{\vv_1,\vv_2}\text{.}\)</span> Once we had the coordinates of <span class="process-math">\(\bb\)</span> with respect to the eigenbasis, then finding <span class="process-math">\(A\bb\)</span> amounted to multiplying <span class="process-math">\(c_1\)</span> and <span class="process-math">\(c_2\)</span> by <span class="process-math">\(\lambda_1\)</span> and <span class="process-math">\(\lambda_2\)</span> respectively. In matrix notation, this is equivalent to computing</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html">
\begin{equation*}
D\mqty[c_1 \\ c_2]\text{ where } D = \mqty[\lambda_1 &amp; 0 \\ 0 &amp; \lambda_2]\text{.}
\end{equation*}
</div>
<div class="para">Finally, we used the weights <span class="process-math">\(\lambda_1 c_1, \lambda_2 c_2\)</span> to reconstruct <span class="process-math">\(A\bb\)</span> from <span class="process-math">\(\vv_1,\vv_2\text{:}\)</span>
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html">
\begin{equation*}
A\bb = \lambda_1 c_1\vv_1 + \lambda_2 c_2\vv_2\text{.}
\end{equation*}
</div>
<div class="para">Therefore</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html" id="md-16">
\begin{align*}
A\bb &amp; = \lambda_1 c_1\vv_1 + \lambda_2 c_2\vv_2\\
&amp; = P\mqty[\lambda_1c_1 \\ \lambda_2c_2] \\
&amp; = PD\mqty[c_1 \\ c_2] \\
&amp; = PDP^{-1}\bb \text{.}
\end{align*}
</div>
<div class="para">Since this equation is true for any <span class="process-math">\(\bb\in\RR^2\text{,}\)</span> it follows that <span class="process-math">\(A = PDP^{-1}\text{.}\)</span>
</div>
</div>
<div class="para logical" id="p-243">
<div class="para">The process outlined above and in <a href="" class="xref" data-knowl="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html" title="Example 2.4.1: Using an Eigenbasis to Compute a Matrix Product">Example¬†2.4.1</a> is known as <em class="emphasis">diagonalization</em>. This is only possible when <span class="process-math">\(A\)</span> has an eigenbasis to work with, but can lead to vastly more efficient computations involving <span class="process-math">\(A\)</span> by making use of the formula</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html ./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html">
\begin{equation*}
A^n = PD^nP^{-1}
\end{equation*}
</div>
<div class="para">since raising diagonal matrices to a power is much simpler than raising general matrices to a power. Finding <span class="process-math">\(A^{100}\bb\)</span> in <a href="" class="xref" data-knowl="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html" title="Example 2.4.1: Using an Eigenbasis to Compute a Matrix Product">Example¬†2.4.1</a> was equivalent to the following computations:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html ./knowl/example-using-an-eigenbasis-to-compute-a-matrix-product.html" id="md-17">
\begin{align*}
A^{100}\bb &amp; = PD^{100}P^{-1}\bb \\
&amp; = \mqty[1 &amp; 3 \\ 1 &amp; 4]\mqty[1^{100} &amp; 0 \\ 0 &amp; 2^{100}]\mqty[4 &amp; -3 \\ -1 &amp; 1]\mqty[-2 \\ 10] \\
&amp; = \mqty[1 &amp; 3 \\ 1 &amp; 4]\mqty[1 &amp; 0 \\ 0 &amp; 2^{100}]\mqty[-38 \\ 12] \\
&amp; = \mqty[1 &amp; 3 \\ 1 &amp; 4]\mqty[-38 \\ 12(2^{100})] \\
&amp; = \mqty[-38 + 36(2^{100}) \\ -38 + 48(2^{100})] \text{.}
\end{align*}
</div>
</div>
<article class="definition definition-like" id="definition-diagonalization"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.4.3</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalization.</span>
</h4> <div class="para logical" id="p-244">
<div class="para">A matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">diagonalizable</dfn> if there exists a matrix <span class="process-math">\(P\)</span> and a diagonal matrix <span class="process-math">\(D\)</span> such that</div>
<div class="displaymath process-math">
\begin{equation*}
A = PDP^{-1}\text{.}
\end{equation*}
</div>
</div></article><div class="para" id="p-245">As mentioned above, a matrix <span class="process-math">\(A\)</span> is diagonalizable if and only if <span class="process-math">\(A\)</span> has an eigenbasis.</div>
<article class="theorem theorem-like" id="theorem-diagonalization-and-eigenbases"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.4</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalization and Eigenbases.</span>
</h4>
<div class="para" id="p-246">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix. Then <span class="process-math">\(A\)</span> is diagonalizable if and only if <span class="process-math">\(A\)</span> has a corresponding eigenbasis <span class="process-math">\(\qty{\vv_i}_{i=1}^n\text{.}\)</span>
</div></article><article class="hiddenproof" id="proof-6"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-6"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-6"><article class="hiddenproof"><div class="para logical" id="p-247">
<div class="para">First, assume that <span class="process-math">\(A\)</span> is diagonalizble. Then there exist matrices <span class="process-math">\(P\)</span> and <span class="process-math">\(D\text{,}\)</span> say</div>
<div class="displaymath process-math">
\begin{equation*}
P = \mqty[\vv_1&amp;\ldots&amp;\vv_n]\text{ and }D = \mqty[\lambda_1 &amp; 0 &amp; \ldots &amp; 0 \\ 0 &amp; \lambda_2 &amp; \ldots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \ldots &amp; \lambda_n]
\end{equation*}
</div>
<div class="para">such that <span class="process-math">\(P\)</span> is invertible and <span class="process-math">\(A = PDP^{-1}\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-248">
<div class="para">We want to show that <span class="process-math">\(A\)</span> must have an eigenbasis. We'll do this by showing that each column <span class="process-math">\(\vv_i\)</span> of <span class="process-math">\(P\)</span> must be an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda_i\text{.}\)</span> Now, since <span class="process-math">\(\vv_i = 0\vv_1 + 0\vv_2 + \cdots + 1\vv_i + \cdots + 0\vv_n\)</span> it follows that <span class="process-math">\(P^{-1}\vv_i\)</span> must be the vector with a single <span class="process-math">\(1\)</span> in the <span class="process-math">\(i^\th\)</span> entry and <span class="process-math">\(0\)</span>s elsewhere. Therefore</div>
<div class="displaymath process-math" id="md-18">
\begin{align*}
A\vv_i &amp; = PDP^{-1}\vv_i \\
&amp; = PD\mqty[0\\0\\\vdots\\1\\\vdots\\0] \\
&amp; = P\mqty[0\\0\\\vdots\\\lambda_i\\\vdots\\0] \\
&amp; = \lambda_i\vv_i 
\end{align*}
</div>
<div class="para">and so <span class="process-math">\(\vv_i\)</span> must be an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda_i\)</span> for each <span class="process-math">\(i\)</span> from <span class="process-math">\(1\)</span> to <span class="process-math">\(n\text{.}\)</span> Since each column of <span class="process-math">\(P\)</span> is an eigenvector of <span class="process-math">\(A\)</span> and since <span class="process-math">\(P\)</span> is invertible, it follows that the columns must be a basis and, hence, an eigenbasis for <span class="process-math">\(A\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-249">
<div class="para">Now we prove the reverse direction. So assume that <span class="process-math">\(A\)</span> has an eigenbasis <span class="process-math">\(\qty{\vv_i}_{i=1}^n\)</span> with corresponding eigenvalues <span class="process-math">\(\qty{\lambda_i}_{i=1}^n\text{.}\)</span> We will show that <span class="process-math">\(A\)</span> is diagonalized by</div>
<div class="displaymath process-math">
\begin{equation*}
P = \mqty[\vv_1&amp;\ldots&amp;\vv_n]\text{ and }D = \mqty[\lambda_1 &amp; 0 &amp; \ldots &amp; 0 \\ 0 &amp; \lambda_2 &amp; \ldots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0 &amp; \ldots &amp; \lambda_n]\text{.}
\end{equation*}
</div>
<div class="para">Let <span class="process-math">\(\xx\in\RR^n\text{.}\)</span> Then we can find the coordinates of <span class="process-math">\(\xx\)</span> with respect to the eigenbasis <span class="process-math">\(\qty{\vv_i}\)</span> by computing <span class="process-math">\(P^{-1}\xx\text{.}\)</span> <aside class="aside aside-like" id="aside-6"><div class="para" id="p-250">Note that <span class="process-math">\(P\)</span> is invertible since its columns form a basis!</div></aside> It follows that applying <span class="process-math">\(A\)</span> to <span class="process-math">\(\xx\)</span> is equivalent to applying <span class="process-math">\(PD\)</span> to <span class="process-math">\(P^{-1}\xx\text{:}\)</span> <span class="process-math">\(DP^{-1}\xx\)</span> will multiply the coordinates of <span class="process-math">\(\xx\)</span> with respect to the eigenbasis by the corresponding eigenvalues, and <span class="process-math">\(PDP^{-1}\xx\)</span> reconstructs <span class="process-math">\(A\xx\)</span> using the weights <span class="process-math">\(DP^{-1}\xx\)</span> to form a linear combination of the columns of <span class="process-math">\(P\text{.}\)</span> Therefore <span class="process-math">\(A\xx=PDP^{-1}\xx\)</span> and so <span class="process-math">\(A = PDP^{-1}\text{.}\)</span>
</div>
</div></article></div>
<article class="example example-like" id="example-diagonalizing-a-matrix"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.5</span><span class="period">.</span><span class="space"> </span><span class="title">Diagonalizing a Matrix.</span>
</h4>
<div class="para logical" id="p-251">
<div class="para">Find matrices <span class="process-math">\(P\)</span> and <span class="process-math">\(D\)</span> (if possible) that diagonalize</div>
<div class="displaymath process-math">
\begin{equation*}
A = \mqty[2 &amp; -1 &amp; -1 \\ -1 &amp; 2 &amp; -1 \\ -1 &amp; -1 &amp; 2]\text{.}
\end{equation*}
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-28" id="solution-28"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-28"><div class="solution solution-like">
<div class="para logical" id="p-252">
<div class="para">By <a href="" class="xref" data-knowl="./knowl/theorem-diagonalization-and-eigenbases.html" title="Theorem 2.4.4: Diagonalization and Eigenbases">Theorem¬†2.4.4</a>, <span class="process-math">\(A\)</span> is diagonalizble if and only if <span class="process-math">\(A\)</span> has an eigenbasis. Using Octave we quickly see that the eigenvalues of <span class="process-math">\(A\)</span> are <span class="process-math">\(\lambda_1 = 0, \lambda_2 = \lambda_3 = 3\text{.}\)</span> Now we need to <span class="process-math">\(\smqty[A - 0I &amp; \vb{0}]\)</span> and <span class="process-math">\(\smqty[A - 3I &amp; \vb{0}]\text{:}\)</span>
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/theorem-diagonalization-and-eigenbases.html">
\begin{equation*}
\mqty[A&amp;\vb{0}] \sim \mqty[1 &amp; 0 &amp; -1 &amp; 0 \\ 0 &amp; 1 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0]\text{ and }\mqty[A-3I &amp; \vb{0}] \sim \mqty[1 &amp; 1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0]\text{.}
\end{equation*}
</div>
<div class="para">Therefore</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/theorem-diagonalization-and-eigenbases.html">
\begin{equation*}
\nul(A) = \spn{\qty{\mqty[1\\1\\1]}}\text{ and }\nul(A-3I) = \spn{\left\{\mqty[-1\\1\\0],\mqty[-1\\0\\1]\right\}}\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="p-253">
<div class="para">Now we have everything we need to diagonalize <span class="process-math">\(A\text{.}\)</span> Define</div>
<div class="displaymath process-math">
\begin{equation*}
P = \mqty[1 &amp; -1 &amp; -1 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1]\text{ and }D = \mqty[0 &amp; 0 &amp; 0 \\ 0 &amp; 3 &amp; 0 \\ 0 &amp; 0 &amp; 3]\text{.}
\end{equation*}
</div>
<div class="para">Then <span class="process-math">\(A = PDP^{-1}\text{.}\)</span>
</div>
</div>
</div></div>
</div></article><pre class="ptx-sagecell sagecell-octave" id="sage-17"><script type="text/x-sage"># code cell to use for previous example
A = [2, -1, -1; -1, 2, -1; -1, -1, 2]
eig(A)
</script></pre></section><section class="subsection" id="subsection-diagonalizations-of-symmetric-and-hermitian-matrices"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Diagonalizations of Symmetric and Hermitian Matrices</span>
</h3>
<div class="para" id="p-254">Symmetric matrices have particularly nice diagonalizations. First, their eigenvalues must be limited to real numbers.</div>
<article class="theorem theorem-like" id="theorem-eigenvalues-of-symmetric-matrices"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.6</span><span class="period">.</span><span class="space"> </span><span class="title">Eigenvalues of Symmetric Matrices.</span>
</h4>
<div class="para" id="p-255">Let <span class="process-math">\(A\)</span> be a symmetric matrix with real entries and let <span class="process-math">\(\lambda\)</span> be an eigenvalue of <span class="process-math">\(A\text{.}\)</span> Then <span class="process-math">\(\lambda\)</span> must be a real number.</div></article><div class="para" id="p-256">The proof of <a href="" class="xref" data-knowl="./knowl/theorem-eigenvalues-of-symmetric-matrices.html" title="Theorem 2.4.6: Eigenvalues of Symmetric Matrices">Theorem¬†2.4.6</a> is relatively simple but requires us to expand our terminology and notation a bit. First, we redefine the inner product so that it also applies to complex vectors in <span class="process-math">\(\CC^n\text{.}\)</span>
</div>
<article class="definition definition-like" id="definition-complex-inner-product"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.4.7</span><span class="period">.</span><span class="space"> </span><span class="title">Complex Inner Product.</span>
</h4> <div class="para logical" id="p-257">
<div class="para">Let <span class="process-math">\(\xx,\yy\in\CC^n\text{.}\)</span> The <dfn class="terminology">(complex) inner product</dfn> of <span class="process-math">\(\xx\)</span> and <span class="process-math">\(\yy\)</span> is the (complex) scalar</div>
<div class="displaymath process-math">
\begin{equation*}
\langle\xx,\yy\rangle = \yy^{*}\xx
\end{equation*}
</div>
<div class="para">where <span class="process-math">\(\yy^*\)</span> denotes the <dfn class="terminology">conjugate transpose</dfn> of <span class="process-math">\(\yy\text{.}\)</span>
</div>
</div></article><div class="para" id="p-258">Now we expand our definition of symmetric matrices to include the complex case as well.</div>
<article class="definition definition-like" id="definition-hermitian-matrices"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">2.4.8</span><span class="period">.</span><span class="space"> </span><span class="title">Hermitian Matrices.</span>
</h4> <div class="para" id="p-259">Let <span class="process-math">\(A\)</span> denote a square matrix. Then <span class="process-math">\(A\)</span> is <dfn class="terminology">Hermitian</dfn> if <span class="process-math">\(A = A^{*}\text{.}\)</span>
</div></article><div class="para" id="p-260">
<a href="" class="xref" data-knowl="./knowl/definition-hermitian-matrices.html" title="Definition 2.4.8: Hermitian Matrices">Definition¬†2.4.8</a> generalizes the definition of a real symmetric matrix since <span class="process-math">\(A^* = A^T\)</span> if <span class="process-math">\(A\)</span> only has real entries. The conjugate transpose and inner product also share many properties, including the following.</div>
<article class="proposition theorem-like" id="proposition-conjugate-transpose-and-inner-product"><h4 class="heading">
<span class="type">Proposition</span><span class="space"> </span><span class="codenumber">2.4.9</span><span class="period">.</span><span class="space"> </span><span class="title">Conjugate Transpose and Inner Product.</span>
</h4>
<div class="para logical" id="p-261">
<div class="para">Let <span class="process-math">\(\xx,\yy\in\CC^n\)</span> and let <span class="process-math">\(A\)</span> be a square matrix with complex entries. Then</div>
<div class="displaymath process-math">
\begin{equation*}
\langle A\xx,\yy\rangle = \dotprod{\xx,A^*\yy}\text{.}
\end{equation*}
</div>
</div></article><div class="para" id="p-262">Now we can prove that real symmetric matrices, and more generally Hermitian matrices, always have real eigenvalues.</div>
<article class="theorem theorem-like" id="theorem-eigenvalues-of-a-hermitian-matrix"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.10</span><span class="period">.</span><span class="space"> </span><span class="title">Eigenvalues of a Hermitian Matrix.</span>
</h4>
<div class="para" id="p-263">Let <span class="process-math">\(A\)</span> denote a Hermitian matrix. Then <span class="process-math">\(A\)</span> has real eigenvalues.</div></article><article class="hiddenproof" id="proof-7"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-7"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-7"><article class="hiddenproof"><div class="para logical" id="p-264">
<div class="para">Let <span class="process-math">\(\xx\)</span> denote an eigenvector of <span class="process-math">\(A\)</span> with eigenvalue <span class="process-math">\(\lambda\text{.}\)</span> Then</div>
<div class="displaymath process-math" id="md-19">
\begin{align*}
\lambda\dotprod{\xx,\xx} &amp; = \dotprod{\lambda\xx,\xx} \\
&amp; = \dotprod{A\xx,\xx} \\
&amp; = \dotprod{\xx, A^*\xx} \\
&amp; = \dotprod{\xx, A\xx} \\
&amp; = \dotprod{\xx, \lambda \xx} \\
&amp; = \overline{\lambda}\dotprod{\xx, \xx} 
\end{align*}
</div>
<div class="para">Since <span class="process-math">\(\dotprod{\xx,\xx} = \norm{\xx}^2\neq0\text{,}\)</span> it follows that <span class="process-math">\(\lambda = \overline{\lambda}\text{.}\)</span> Therefore <span class="process-math">\(\lambda\in\RR\text{.}\)</span>
</div>
</div></article></div>
<div class="para" id="p-265">The eigenvectors of a Hermitian matrix also have nice geometric properties.</div>
<article class="theorem theorem-like" id="theorem-eigenvectors-of-a-hermitian-matrix"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.11</span><span class="period">.</span><span class="space"> </span><span class="title">Eigenvectors of a Hermitian Matrix.</span>
</h4>
<div class="para" id="p-266">Let <span class="process-math">\(A\)</span> be a Hermitian matrix. Suppose that <span class="process-math">\(\xx\)</span> and <span class="process-math">\(\yy\)</span> are eigenvectors for two distinct eigenvalues of <span class="process-math">\(A\text{,}\)</span> say <span class="process-math">\(\lambda_i\)</span> and <span class="process-math">\(\lambda_j\text{.}\)</span> Then <span class="process-math">\(\xx\)</span> and <span class="process-math">\(\yy\)</span> are orthogonal.</div></article><article class="hiddenproof" id="proof-8"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-8"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-8"><article class="hiddenproof"><div class="para logical" id="p-267">
<div class="para">We need to show that <span class="process-math">\(\dotprod{\xx,\yy} = 0\text{.}\)</span> Now,</div>
<div class="displaymath process-math">
\begin{equation*}
\lambda_i\dotprod{\xx,\yy} = \dotprod{A\xx,\yy} = \dotprod{\xx,A\yy} = \lambda_j\dotprod{\xx,\yy}
\end{equation*}
</div>
<div class="para">or just <span class="process-math">\((\lambda_i-\lambda_j)\dotprod{\xx,\yy} = 0\text{.}\)</span> Since <span class="process-math">\(\lambda_i\neq \lambda_j\text{,}\)</span> it follows that <span class="process-math">\(\dotprod{\xx,\yy} = 0\text{.}\)</span>
</div>
</div></article></div>
<div class="para logical" id="p-268">
<div class="para">
<a href="" class="xref" data-knowl="./knowl/theorem-eigenvectors-of-a-hermitian-matrix.html" title="Theorem 2.4.11: Eigenvectors of a Hermitian Matrix">Theorem¬†2.4.11</a> leads to an extremely useful fact about real symmetric matrices: they can always be <em class="emphasis">orthogonally diagonalized</em>. This means that we can choose an eigenbasis that is also an orthonormal basis. As an example, consider the eigenbasis found in <a href="" class="xref" data-knowl="./knowl/example-diagonalizing-a-matrix.html" title="Example 2.4.5: Diagonalizing a Matrix">Example¬†2.4.5</a>, replicated here as columns of the matrix <span class="process-math">\(P\text{:}\)</span>
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/theorem-eigenvectors-of-a-hermitian-matrix.html ./knowl/example-diagonalizing-a-matrix.html ./knowl/theorem-eigenvectors-of-a-hermitian-matrix.html">
\begin{equation*}
P = \mqty[1 &amp; -1 &amp; -1 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1]\text{.}
\end{equation*}
</div>
<div class="para">Note that the first column is orthogonal to the other two which is guaranteed by <a href="" class="xref" data-knowl="./knowl/theorem-eigenvectors-of-a-hermitian-matrix.html" title="Theorem 2.4.11: Eigenvectors of a Hermitian Matrix">Theorem¬†2.4.11</a> since these vectors correspond to different eigenvalues.</div>
</div>
<div class="para logical" id="p-269">
<div class="para">Although the last two columns are not orthogonal, they can be <em class="emphasis">orthogonalized</em>. One way of doing so is to replace them with the vectors</div>
<div class="displaymath process-math">
\begin{equation*}
\mqty[-1\\1\\0]\text{ and }\mqty[-\frac{1}{2} \\ -\frac{1}{2} \\ 1] = \mqty[-1\\0\\1]-\frac{1}{2}\mqty[-1\\1\\0]\text{.}
\end{equation*}
</div>
<div class="para">Both vectors are still eigenvectors with eigenvalue <span class="process-math">\(0\)</span> and the two of them, together with <span class="process-math">\(\smqty[1\\1\\1]\text{,}\)</span> still form an eigenbasis of <span class="process-math">\(\RR^3\text{.}\)</span> However, this new basis is orthogonal.</div>
</div>
<div class="para logical" id="p-270">
<div class="para">If we go one step further and normalize the vectors in this eigenbasis we then get the orthonormal eigenbasis</div>
<div class="displaymath process-math">
\begin{equation*}
\qty{\mqty[\frac{1}{\sqrt{3}} \\ \frac{1}{\sqrt{3}} \\ \frac{1}{\sqrt{3}}], \mqty[-\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} \\ 0], \mqty[-\frac{1}{\sqrt{6}} \\ -\frac{1}{\sqrt{6}} \\ \sqrt{\frac{2}{3}}]}\text{.}
\end{equation*}
</div>
<div class="para">This provides the orthogonal diagonalization</div>
<div class="displaymath process-math">
\begin{equation*}
U = \mqty[\frac{1}{\sqrt{3}} &amp; -\frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{6}} \\ \frac{1}{\sqrt{3}} &amp; \frac{1}{\sqrt{2}} &amp; -\frac{1}{\sqrt{6}} \\ \frac{1}{\sqrt{3}} &amp; 0 &amp; \sqrt{\frac{2}{3}}]\text{ and }D = \mqty[0 &amp; 0 &amp; 0 \\ 0 &amp; 3 &amp; 0 \\ 0 &amp; 0 &amp; 3]
\end{equation*}
</div>
<div class="para">which gives</div>
<div class="displaymath process-math">
\begin{equation*}
A = UDU^{-1} = UDU^T\text{.}
\end{equation*}
</div>
<div class="para">Such a diagonalization is always possible for real symmetric and Hermitian matrices, a result known as the <em class="emphasis">Spectral Theorem</em>.</div>
</div>
<article class="theorem theorem-like" id="theorem-spectral-theorem"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.12</span><span class="period">.</span><span class="space"> </span><span class="title">Spectral Theorem.</span>
</h4>
<div class="para logical" id="p-271">
<div class="para">Let <span class="process-math">\(A\)</span> be a (real) symmetric matrix. Then there exists an orthogonal matrix <span class="process-math">\(U\)</span> and a diagonal matrix <span class="process-math">\(D\)</span> such that</div>
<div class="displaymath process-math">
\begin{equation*}
A = UDU^T\text{.}
\end{equation*}
</div>
<div class="para">Equivalently, if <span class="process-math">\(\qty{\uu_i}_{i=1}^n\)</span> is an orthonormal eigenbasis of <span class="process-math">\(A\)</span> with corresponding eigenvalues <span class="process-math">\(\qty{\lambda_i}_{i=1}^n\text{,}\)</span> then</div>
<div class="displaymath process-math">
\begin{equation*}
A = \sum_{i=1}^n \lambda_i \uu_i\uu_i^T\text{.}
\end{equation*}
</div>
</div></article><article class="example example-like" id="example-a-signal-processing-application"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.13</span><span class="period">.</span><span class="space"> </span><span class="title">A Signal Processing Application.</span>
</h4>
<div class="para logical" id="p-272">
<div class="para">In the mathematics of signal processing, signals are often represented as particular vectors in <span class="process-math">\(\RR^n\text{.}\)</span> The problem of signal transmission then reduces to sending a list of numbers <span class="process-math">\(c_1,\ldots, c_m\)</span> such that the receiver can use these to reconstruct a signal <span class="process-math">\(\xx\text{.}\)</span> Such a scheme can be implemented by choosing an appropriate <span class="process-math">\(n\times m\)</span> matrix <span class="process-math">\(F = \smqty[\vb{f}_1 &amp; \ldots &amp; \vb{f}_m]\)</span> and then computing and transmitting the coordinates of</div>
<div class="displaymath process-math">
\begin{equation*}
F^T\xx = \mqty[\langle \xx,\vb{f}_i\rangle]_{1\leq i\leq m}\text{.}
\end{equation*}
</div>
<div class="para">The important properties of the columns of <span class="process-math">\(F\)</span> can then be encoded in the <em class="emphasis">Gram matrix</em> <span class="process-math">\(G = F^TF = \mqty[\dotprod{\vb{f}_i,\vb{f}_j}]\text{.}\)</span> Find a <span class="process-math">\(3\times 4\)</span> matrix <span class="process-math">\(F\)</span> for which that Gram matrix is</div>
<div class="displaymath process-math">
\begin{equation*}
G = \mqty[1 &amp; -\frac{1}{3} &amp; -\frac{1}{3} &amp; -\frac{1}{3} \\ -\frac{1}{3} &amp; 1 &amp; -\frac{1}{3} &amp; -\frac{1}{3} \\ -\frac{1}{3} &amp; -\frac{1}{3} &amp; 1 &amp; -\frac{1}{3} \\ -\frac{1}{3} &amp; -\frac{1}{3} &amp; -\frac{1}{3} &amp; 1]\text{.}
\end{equation*}
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-29" id="solution-29"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-29"><div class="solution solution-like"><div class="para" id="p-273">This problem can be solved by diagonalizing <span class="process-math">\(G\text{:}\)</span> if <span class="process-math">\(G = UDU^T\)</span> then we can define <span class="process-math">\(F\)</span> by using the rows of <span class="process-math">\(U\sqrt{D}\text{.}\)</span> <aside class="aside aside-like" id="aside-7"><div class="para" id="p-274">If <span class="process-math">\(D\)</span> is diagonal with nonnegative entries, then we can define <span class="process-math">\(\sqrt{D}\)</span> to be the matrix obtained by taking the square root of each entry of <span class="process-math">\(D\text{.}\)</span> It's not obvious, but it turns out that Gram matrices always have nonnegative eigenvalues. If we diagonalize <span class="process-math">\(G\)</span> and find it has negative eigenvalues, then it cannot be a Gram matrix.</div></aside> So we'll diagonalize <span class="process-math">\(G\)</span> with the help of the Octave cell below. Doing so, we see that the eigenvalues of <span class="process-math">\(G\)</span> are in fact nonnegative and so <span class="process-math">\(U\sqrt{D}\)</span> will only contain real values. Furthermore, <span class="process-math">\(U\)</span> only has <span class="process-math">\(3\)</span> nonzero columns since <span class="process-math">\(G\)</span> only has three nonzero eigenvalues. By removing the zero column from <span class="process-math">\(U\sqrt{D}\text{,}\)</span> we obtain a <span class="process-math">\(4\times3\)</span> matrix which we define to be <span class="process-math">\(F^T\text{.}\)</span> Then <span class="process-math">\(F^TF = G\text{.}\)</span>
</div></div></div>
</div></article><pre class="ptx-sagecell sagecell-octave" id="sage-18"><script type="text/x-sage"># diagonalizing a Gram matrix
format short
G = (4/3)*eye(4) - (1/3)*ones(4) # tricky way to define G
</script></pre>
<div class="para logical" id="p-275">
<div class="para">Symmetric matrices are also useful in analyzing <em class="emphasis">quadratic forms</em>, which are expressions of the form</div>
<div class="displaymath process-math">
\begin{equation*}
\sum_{i,j}c_{ij} x_ix_j
\end{equation*}
</div>
<div class="para">where the <span class="process-math">\(x_i\)</span> are variables and the <span class="process-math">\(c_{ij}\)</span> are the coefficients. Such an expression can be rewritten as <span class="process-math">\(\xx^T A\xx\)</span> where <span class="process-math">\(A\)</span> is a symmetric matrix determined from the coefficients.</div>
</div>
<article class="example example-like" id="example-analyzing-a-quadratic-form"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.14</span><span class="period">.</span><span class="space"> </span><span class="title">Analyzing a Quadratic Form.</span>
</h4>
<div class="para logical" id="p-276">
<div class="para">Describe the curve given by</div>
<div class="displaymath process-math">
\begin{equation*}
9x^2 + 6xy + y^2 = 10\text{.}
\end{equation*}
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-30" id="solution-30"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-30"><div class="solution solution-like">
<div class="para logical" id="p-277">
<div class="para">The left hand side is a quadratic form with variables <span class="process-math">\(x_1 = x,x_2 = y\)</span> and coefficients</div>
<div class="displaymath process-math">
\begin{equation*}
c_{11} = 9, c_{12} = c_{21} = \frac{6}{2}=3\text{ and }c_{22} = 1\text{.}
\end{equation*}
</div>
<div class="para">Therefore we can write <span class="process-math">\(9x^2 + 6xy + y^2 = \xx^T A\xx\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
\xx = \mqty[x\\y]\text{ and }A = \mqty[9 &amp; 3 \\ 3 &amp; 1]\text{.}
\end{equation*}
</div>
<div class="para">To help us describe the curve we will ‚Äúdisentangle‚Äù the variables <span class="process-math">\(x\)</span> and <span class="process-math">\(y\)</span> by diagonalizing <span class="process-math">\(A\text{.}\)</span>
</div>
</div> <div class="para logical" id="p-278">
<div class="para">Since <span class="process-math">\(A\)</span> is symmetric, we know that <span class="process-math">\(A\)</span> can be orthogonally diagonalized. One such diagonalization is given by <span class="process-math">\(A = UDU^T\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
U = \mqty[\frac{1}{\sqrt{10}} &amp; \frac{3}{\sqrt{10}} \\ -\frac{3}{\sqrt{10}} &amp; \frac{1}{\sqrt{10}}]\text{ and } D = \mqty[0 &amp; 0 \\ 0 &amp; 10]\text{.}
\end{equation*}
</div>
<div class="para">The quadratic form <span class="process-math">\(\xx^T A\xx\)</span> then becomes</div>
<div class="displaymath process-math">
\begin{equation*}
\xx^T UDU^T\xx = (U^T\xx)^T D (U^T \xx)\text{.}
\end{equation*}
</div>
</div> <div class="para logical" id="p-279">
<div class="para">Now we define <span class="process-math">\(\yy = U^T\xx\)</span> as a change-of-variables. In particular,</div>
<div class="displaymath process-math">
\begin{equation*}
\yy = \mqty[X\\Y] = \mqty[\frac{1}{\sqrt{10}}x - \frac{3}{\sqrt{10}}y \\ \frac{3}{\sqrt{10}}x + \frac{1}{\sqrt{10}}y]\text{.}
\end{equation*}
</div>
<div class="para">Our quadratic form is now</div>
<div class="displaymath process-math">
\begin{equation*}
\yy^T D\yy = 0X^2 + 10Y^2 = 10Y^2
\end{equation*}
</div>
<div class="para">and our original equation becomes <span class="process-math">\(10Y^2 = 10\)</span> or just <span class="process-math">\(Y = \pm1\text{.}\)</span> Therefore the original equation describes the two different lines</div>
<div class="displaymath process-math">
\begin{equation*}
\frac{3}{\sqrt{10}}x + \frac{1}{\sqrt{10}}y = -1\text{ and }\frac{3}{\sqrt{10}}x + \frac{1}{\sqrt{10}}y = 1\text{.}
\end{equation*}
</div>
</div>
</div></div>
</div></article></section><section class="subsection" id="subsection-analytic-functions-of-matrices"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber"></span> <span class="title">Analytic Functions of Matrices</span>
</h3>
<div class="para logical" id="p-280">
<div class="para">A function <span class="process-math">\(f(x)\)</span> is <em class="emphasis">analytic</em> at <span class="process-math">\(x = a\)</span> if it has a power series representation on some interval centered around <span class="process-math">\(a\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
f(x) = \sum_{k=0}^\infty c_k(x-a)^k = c_0 + c_1(x-a) + c_2(x-a)^2 + \cdots\text{ for }x\approx a\text{.}
\end{equation*}
</div>
<div class="para">If <span class="process-math">\(A\)</span> denotes a square matrix, and if <span class="process-math">\(f(x)\)</span> is analytic at <span class="process-math">\(a=0\text{,}\)</span> then we can try to make sense of the expression <span class="process-math">\(f(A)\)</span> by using the power series for <span class="process-math">\(f(x)\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
f(A) = \sum_{k=0}^{\infty}c_k A^k = c_0I + c_1A + c_2A^2 + \cdots\text{,}
\end{equation*}
</div>
<div class="para">assuming this sum actually exists.</div>
</div>
<article class="example example-like" id="example-exponential-of-a-matrix"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.15</span><span class="period">.</span><span class="space"> </span><span class="title">Exponential of a Matrix.</span>
</h4>
<div class="para logical" id="p-281">
<div class="para">Let</div>
<div class="displaymath process-math">
\begin{equation*}
A = \mqty[0 &amp; 2 &amp; 3 \\ 0 &amp; 0 &amp; 2 \\ 0 &amp; 0 &amp; 0]\text{.}
\end{equation*}
</div>
<div class="para">Find <span class="process-math">\(e^A\text{.}\)</span>
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-31" id="solution-31"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-31"><div class="solution solution-like"><div class="para logical" id="p-282">
<div class="para">By definition,</div>
<div class="displaymath process-math">
\begin{equation*}
e^A = I + A + \frac{1}{2!}A^2 + \frac{1}{3!}A^3 + \cdots\text{,}
\end{equation*}
</div>
<div class="para">so we can find <span class="process-math">\(e^A\)</span> by looking at the powers of <span class="process-math">\(A\text{.}\)</span> In this case,</div>
<div class="displaymath process-math">
\begin{equation*}
A^2 = \mqty[0 &amp; 0 &amp; 4 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0]\text{ and }A^3 = A^4 = \ldots = \mqty[0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0]\text{.}
\end{equation*}
</div>
<div class="para">Therefore</div>
<div class="displaymath process-math">
\begin{equation*}
e^A = I + A + \frac{1}{2}A^2 = \mqty[1 &amp; 2 &amp; 5 \\ 0 &amp; 1 &amp; 2 \\ 0 &amp; 0 &amp; 1]\text{.}
\end{equation*}
</div>
<div class="para">This can be verified using the command <code class="code-inline tex2jax_ignore">expm</code> in Octave as below. <aside class="aside aside-like" id="aside-8"><div class="para" id="p-283">You want to be careful to use <code class="code-inline tex2jax_ignore">expm(A)</code> to compute <span class="process-math">\(e^A\)</span> in Octave, as this actually finds the matrix exponential. If you instead use <code class="code-inline tex2jax_ignore">exp(A)</code>, this just computes the matrix obtained by raising <span class="process-math">\(e\)</span> to each entry of <span class="process-math">\(A\text{,}\)</span> which in general is <em class="emphasis">not</em> equal to <span class="process-math">\(e^A\text{.}\)</span>
</div></aside>
</div>
</div></div></div>
</div></article><pre class="ptx-sagecell sagecell-octave" id="sage-19"><script type="text/x-sage">format short
A = [0, 2, 3; 0, 0, 2; 0, 0, 0]
expm(A) # don't use exp(A)! that just exponentiates each entry of A
</script></pre>
<article class="example example-like" id="example-function-of-a-diagonal-matrix"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.16</span><span class="period">.</span><span class="space"> </span><span class="title">Function of a Diagonal Matrix.</span>
</h4>
<div class="para" id="p-284">Let <span class="process-math">\(f(x)\)</span> be a function analytic at <span class="process-math">\(0\text{.}\)</span> Let <span class="process-math">\(D\)</span> be a diagonal matrix whose diagonal entries are within the interval of convergence of the power series for <span class="process-math">\(f(x)\)</span> centered at <span class="process-math">\(0\text{.}\)</span> Find <span class="process-math">\(f(D)\text{.}\)</span>
</div></article><div class="para" id="p-285">The last example shows that if <span class="process-math">\(f(x)\)</span> is analytic at <span class="process-math">\(0\)</span> then it is relatively straightforward to find <span class="process-math">\(f(D)\text{,}\)</span> assuming that the diagonal entries of <span class="process-math">\(D\)</span> are within the interval of convergence for the series representation of <span class="process-math">\(f(x)\)</span> at <span class="process-math">\(0\text{.}\)</span> Therefore we can find functions of diagonalizable matrices as well.</div>
<article class="theorem theorem-like" id="theorem-analytic-functions-of-diagonalizable-matrices"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.17</span><span class="period">.</span><span class="space"> </span><span class="title">Analytic Functions of Diagonalizable Matrices.</span>
</h4>
<div class="para logical" id="p-286">
<div class="para">Let <span class="process-math">\(f(x)\)</span> be a function that is analytic at <span class="process-math">\(0\)</span> and whose series representation at <span class="process-math">\(0\)</span> has interval of convergence <span class="process-math">\(I\text{.}\)</span> Let <span class="process-math">\(A\)</span> be a diagonalizable matrix diagonalized by <span class="process-math">\(P\)</span> and <span class="process-math">\(D\)</span> with eigenvalues contained in <span class="process-math">\(I\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
f(A) = Pf(D)P^{-1}\text{.}
\end{equation*}
</div>
</div></article><article class="hiddenproof" id="proof-9"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-9"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-9"><article class="hiddenproof"><div class="para logical" id="p-287">
<div class="para">Let <span class="process-math">\(f(x) = \sum_{k=0}^{\infty}c_k x^k\)</span> and recall that <span class="process-math">\(A^k = PD^kP^{-1}\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
f(A) = \sum_{k=0}^{\infty}c_kA^k = P\qty(\sum_{k=0}^{\infty}c_k D^k)P^{-1} = Pf(D)P^{-1}\text{.}
\end{equation*}
</div>
</div></article></div>
<div class="para" id="p-288">
<a href="" class="xref" data-knowl="./knowl/theorem-analytic-functions-of-diagonalizable-matrices.html" title="Theorem 2.4.17: Analytic Functions of Diagonalizable Matrices">Theorem¬†2.4.17</a> allows for straightforward computations of matrix exponentials of diagonalizable matrices. This is useful in differential equations when solving linear systems of ODEs (see <a class="external" href="https://j-oldroyd.github.io/wvwc-differential-equations/systems-of-odes.html" target="_blank">here</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-3" id="fn-3"><sup>‚Äâ3‚Äâ</sup></a>).</div>
<article class="theorem theorem-like" id="theorem-exponential-solutions-of-linear-systems-of-odes"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">2.4.18</span><span class="period">.</span><span class="space"> </span><span class="title">Exponential Solutions of Linear Systems of ODEs.</span>
</h4>
<div class="para logical" id="p-289">
<div class="para">Let <span class="process-math">\(A\)</span> be a (constant) square matrix and consider the first-order system <span class="process-math">\(\xx^\prime = A\xx\)</span> with initial condition <span class="process-math">\(\xx(0) = \xx_0\text{.}\)</span> Then the solution of this initial value problem is</div>
<div class="displaymath process-math">
\begin{equation*}
\xx(t) = e^{At}\xx_0\text{.}
\end{equation*}
</div>
</div></article><article class="hiddenproof" id="proof-10"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-10"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-10"><article class="hiddenproof"><div class="para logical" id="p-290">
<div class="para">The proof follows quickly from the fact that <span class="process-math">\(\dv{}{t}(e^{At}) = Ae^{At}\text{.}\)</span> Using this, we differentiate <span class="process-math">\(\xx(t) = e^{At}\xx_0\)</span> to get</div>
<div class="displaymath process-math">
\begin{equation*}
\dv{\xx}{t} = Ae^{At}\xx_0 = A\xx\text{.}
\end{equation*}
</div>
<div class="para">Furthermore, <span class="process-math">\(\xx(0) = e^{\vb{0}}\xx_0 = \xx_0\text{.}\)</span> Therefore <span class="process-math">\(\xx(t) = e^{At}\xx_0\)</span> is a solution of the initial value problem.</div>
</div></article></div>
<div class="para" id="p-291">Theorems <a href="" class="xref" data-knowl="./knowl/theorem-analytic-functions-of-diagonalizable-matrices.html" title="Theorem 2.4.17: Analytic Functions of Diagonalizable Matrices">2.4.17</a> and <a href="" class="xref" data-knowl="./knowl/theorem-exponential-solutions-of-linear-systems-of-odes.html" title="Theorem 2.4.18: Exponential Solutions of Linear Systems of ODEs">2.4.18</a> allow us to find solutions of linear systems that involve diagonalizable matrices in terms of the matrix exponential.</div>
<article class="example example-like" id="example-solving-a-first-order-system"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">2.4.19</span><span class="period">.</span><span class="space"> </span><span class="title">Solving a First-Order System.</span>
</h4>
<div class="para logical" id="p-292">
<div class="para">Solve</div>
<div class="displaymath process-math">
\begin{equation*}
x^\prime = 3x - 4y \text{ and } y^\prime = -4x + 3y
\end{equation*}
</div>
<div class="para">with initial condition <span class="process-math">\(x(0) = 2\)</span> and <span class="process-math">\(y(0) = -1\text{.}\)</span>
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-32" id="solution-32"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-32"><div class="solution solution-like"><div class="para logical" id="p-293">
<div class="para">This can be solved very easily using the matrix exponential and diagonalization. If we let</div>
<div class="displaymath process-math">
\begin{equation*}
\xx = \mqty[x \\ y]\text{ and }A = \mqty[3 &amp; -4 \\ -4 &amp; 3]
\end{equation*}
</div>
<div class="para">then the system can be written as the matrix ODE <span class="process-math">\(\xx^\prime = A\xx\)</span> with initial condition <span class="process-math">\(\xx_0 = \smqty[2 \\ 1]\text{.}\)</span> <span class="process-math">\(A\)</span> is symmetric and can be orthogonally diagonalized by</div>
<div class="displaymath process-math">
\begin{equation*}
U = \mqty[\frac{\sqrt{2}}{2} &amp; \frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} &amp; -\frac{\sqrt{2}}{2}]\text{ and } D = \mqty[-1 &amp; 0 \\ 0 &amp; 7]
\end{equation*}
</div>
<div class="para">as seen in the code cell below this example. Therefore <span class="process-math">\(A = UDU^T\text{,}\)</span> <span class="process-math">\(e^{At} = Ue^{Dt}U^T\)</span> and the solution of the system must be</div>
<div class="displaymath process-math">
\begin{equation*}
\xx = \mqty[\frac{\sqrt{2}}{2} &amp; \frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} &amp; -\frac{\sqrt{2}}{2}]\mqty[e^{-t} &amp; 0 \\ 0 &amp; e^{7t}]\mqty[\frac{\sqrt{2}}{2} &amp; \frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} &amp; -\frac{\sqrt{2}}{2}]\mqty[2 \\ -1]\text{.}
\end{equation*}
</div>
</div></div></div>
</div></article><pre class="ptx-sagecell sagecell-octave" id="sage-20"><script type="text/x-sage">format short
A = [3, -4; -4, 3]
[U,D] = eig(A)
</script></pre></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-3"><div class="fn"><code class="code-inline tex2jax_ignore">j-oldroyd.github.io/wvwc-differential-equations/systems-of-odes.html</code></div></div>
</div>
<div class="ptx-content-footer">
<a class="previous-button button" href="section-orthogonal-transformations.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="part-multivariable-calculus.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org"><div class="name">Authored in PreTeXt</div>
<div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259 "></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0  472  9732 "></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496 "></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496 A 4241 4241  0  0  1  4724  3590 "></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259 A 4507 4507  0  0  1  4724  9448 "></path><polyline points="5385,4299 4062,8125 " style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round; "></polyline><polyline points="8598,3496 8598,9259 " style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round; "></polyline><polyline points="850,3496 850,9259 " style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round; "></polyline><polyline points="4960,9685 4488,9685 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><polyline points="3070,4582 1889,6141 3070,7700 " style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round; "></polyline><polyline points="6418,4582 7600,6141 6418,7700 " style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round; "></polyline><polyline points="8976,3590 8976,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732 "></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy"><div class="name">Powered by Runestone</div>
<img class="logo" title="Powered by Runestone" src="https://runestone.academy/runestone/static/rectangle_badge.png" alt="Powered by Runestone"></a><a class="mathjax-logo" href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a>
</div>
</body>
</html>
